{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping reads to genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big><b>File completed </b></big> (05/21/2021) <br>\n",
    "An issue appended with <code>STAR</code> for mapping first sample: <b>I added some cells (thus not to be included in default pipeline)</b> to re-run this sample.  \n",
    "TODO for next use: change counted generated files post-Star mapping, only <code>*.bam</code> files should be better... but do not help when one is empty :/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    Please note, that genome file indexing is appropriate for RNA sequencing of 50-bases reads. <br>\n",
    "    If different, change <code>rawreadlength</code>'s below setted value with your dataset sequenced read length.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <b>Preparing session for IFB core cluster</b>\n",
    "\n",
    "<em>loaded JupyterLab</em> : Version 2.2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cell launched on Thu May 20 13:12:55 CEST 2021 ===\n",
      "=== Current IFB session size: Medium (4CPU, 10GB) or Large (10CPU, 50GB) ===\n",
      "       JobID  AllocCPUS        NodeList \n",
      "------------ ---------- --------------- \n",
      "16677880             10     cpu-node-17 \n",
      "16677880.ba+         10     cpu-node-17 \n",
      "16677880.0           10     cpu-node-17 \n",
      "=== Working's root folder is ===\n",
      "/shared/projects/gonseq/Building/\n",
      "\n",
      "=== current folder tree ===\n",
      "/shared/projects/gonseq/Building/\n",
      "├── Data\n",
      "│   ├── fastq\n",
      "│   ├── info\n",
      "│   └── sra\n",
      "├── Pipeline\n",
      "└── Results\n",
      "    ├── fastp\n",
      "    ├── fastqc\n",
      "    ├── logfiles\n",
      "    └── multiqc\n",
      "\n",
      "10 directories\n",
      "=== current working directory ===\n",
      "/shared/ifbstor1/projects/gonseq/Testing/Pipeline\n"
     ]
    }
   ],
   "source": [
    "echo \"=== Cell launched on $(date) ===\"\n",
    "\n",
    "echo \"=== Current IFB session size: Medium (4CPU, 10GB) or Large (10CPU, 50GB) ===\"\n",
    "jobid=$(squeue -hu $USER | awk '/jupyter/ {print $1}')\n",
    "sacct --format=JobID,AllocCPUS,NODELIST -j ${jobid}\n",
    "\n",
    "echo \"=== Working's root folder is ===\"\n",
    "gohome=\"/shared/projects/gonseq/Building/\" # to adjust with your project's folder\n",
    "echo \"${gohome}\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"=== current folder tree ===\"\n",
    "tree -d -L 2 \"${gohome}\"\n",
    "echo \"=== current working directory ===\"\n",
    "echo \"${PWD}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== download network files =====\n",
      "GNU Wget 1.14 built on linux-gnu.\n",
      "===== alignement tool =====\n",
      "2.7.5a\n",
      "===== index construction + quality =====\n",
      "samtools 1.10\n",
      "Using htslib 1.10.2\n",
      "Copyright (C) 2019 Genome Research Ltd.\n"
     ]
    }
   ],
   "source": [
    "module load star samtools\n",
    "\n",
    "echo \"===== download network files =====\"\n",
    "wget --version | head -n 1\n",
    "echo \"===== alignement tool =====\"\n",
    "STAR --version\n",
    "echo \"===== index construction + quality =====\"\n",
    "samtools --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <b>I- Reference genome and annotation files</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1- Searching for them (their url!) on the web**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several websites to download reference genome and annotation files:\n",
    "- <a href=\"https://www.gencodegenes.org/human/\"><i>Gencode</i></a> from the European Biomolecular Institute (EBI)  \n",
    "- <a href=\"http://www.ensembl.org/info/data/ftp/index.html\"><i>Accessing Ensembl Data</i></a> from Ensembl project database  \n",
    "- <a href=\"https://www.ncbi.nlm.nih.gov/genome/guide/human/\"><i>Human Genome Ressources</i></a> at NCBI  \n",
    "- ... and maybe one day a commom NCBI and Ensembl/Gencode realease (MANE collaboration, <a href=\"https://ncbiinsights.ncbi.nlm.nih.gov/2020/11/02/ncbi-refseq-ensembl-gencode-mane-v0-92/#more-4781\">a story beginning in 2020</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a **Primary assembly** (PRI) release. It includes chromosomes and scaffolds (candidate regions to be integrated or discarded in next genome build).  \n",
    "On the contrary, the main annotation file is limited to chromosomes while the extensive annotation file also includes all hnown haplotypes (for highly variables regions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    In this notebook, we use <b>Gencode release</b>, that provides user with <b><code>.gz</code> compressed</b> files, and we choose <b>GTF format</b> for you annotation file. <br>\n",
    "    Feel free to choose the source you want among above citated ones, as far as downloaded files follow the same file formats (else change next sections code cells!).\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Nonetheless, please note that annotation file format is an actively opened issue as some relevant official sources are contradictory: \n",
    "    <ul>\n",
    "        <li>\n",
    "            For US's Galaxy's project: <a href=\"https://galaxyproject.org/learn/datatypes/#gtf\">GTF</a> is the GFF's version 2 while <a href=\"https://galaxyproject.org/learn/datatypes/#gff\">GFF</a> is version 1 and <a href=\"https://galaxyproject.org/learn/datatypes/#gff3\">GFF3</a> is the latest and 3rd version... \n",
    "        </li>\n",
    "        <li>\n",
    "        ... but IGV Broad Institute, as UCSC genome browser, makes distinction between <a href=\"http://software.broadinstitute.org/software/igv/GFF\">GFF2 and GTF formats</a>, <a href=\"https://genome.ucsc.edu/FAQ/FAQformat.html#format3\"> the later being only compatible with the former</a>.\n",
    "        </li>\n",
    "        <li>\n",
    "            While both <a href=\"https://biocorecrg.github.io/PhD_course/gtf_format.html\">GTF</a> and <a href=\"https://biostar.usegalaxy.org/p/28147/\">GFF</a> formats have 9 columns, field in the ninth column is longer for <code>.gtf</code> files than for <code>.gff</code> files (<a href=\"https://genome.ucsc.edu/FAQ/FAQformat.html#format3\">UCSC Genome browser documentation</a> and <a href=\"https://www.ensembl.org/info/website/upload/gff.html\">ensembl documentation</a>).\n",
    "        </li>\n",
    "        <li>\n",
    "            Even if both file format have header lines, some tools do not support them (<a href=\"https://biostar.usegalaxy.org/p/28147/\">second bullet point in last anwser</a>) and US Galaxy portal ask users to remove those lines before use (see upper US Galaxy's links).\n",
    "        </li>\n",
    "        <li>\n",
    "            <code>FeatureCounts</code> (a downstream tool we will use) only <a href=\"http://bioinf.wehi.edu.au/featureCounts/\">works with GTF files</a>. Tool expects to have <i>exon</i> in <i>features</i> column (both GFF and GTF!) and <i>gene_id</i> as a gene identifier (missing in GFF), see <a href=\"https://biostar.usegalaxy.org/p/28094/index.html#28099\">item 4 in latest answer</a>.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have latest current genome release for your analyses, please go to Gencode's <a href=\"https://www.gencodegenes.org/human/\">download page</a> (or to other chosen reference download page) and adapt url links for:\n",
    "- Primary annotation (notebook developped with GTF file)\n",
    "> in *GTF/GFF3 files* Gencode's chart: Comprehensive gene annotation > primary annotation > *gtf* file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtfgzurl=\"ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/gencode.v37.primary_assembly.annotation.gtf.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primary genome sequence file\n",
    "> in *Fasta files* Gencode's chart: Genome sequence, primary assembly > *Fasta* file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fagzurl=\"ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/GRCh38.primary_assembly.genome.fa.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: You can get url link with a right click on download links, then *copy link to clipboard*.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    Both files have to be retrieved from same source as sequence region names need to be the same in both in order to be useful and avoid dowstream analysis issues. <br>\n",
    "    <i>In Gencode, this files' compatibility is specified in the <b>fasta's description field</b></i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2- Retrieve files with ``wget``**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download those files in a distinct folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reffolder=\"${gohome}Reference/\"\n",
    "mkdir -p ${reffolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"alert alert-block alert-info\">\n",
    "    <li>\n",
    "        Sometimes (often?!), other users issues help us understand a command more than its manual. For instance, a Stackoverflow's <a href=\"https://unix.stackexchange.com/questions/23501/download-using-wget-to-a-different-directory-than-current-directory\">thread</a> about <code>wget</code> command and the way to write into a chosen output folder. \n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some output is redirected to /shared/projects/gonseq/Building/Reference/wget_reference_files_downloads.log for record\n",
      "--2021-05-20 13:12:58--  ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/gencode.v37.primary_assembly.annotation.gtf.gz\n",
      "           => ‘/shared/projects/gonseq/Building/Reference/.listing’\n",
      "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.197.74\n",
      "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.197.74|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /pub/databases/gencode/Gencode_human/release_37 ... done.\n",
      "==> PASV ... done.    ==> LIST ... done.\n",
      "\n",
      "    [ <=>                                   ] 3,928       --.-K/s   in 0.005s  \n",
      "\n",
      "2021-05-20 13:12:58 (742 KB/s) - ‘/shared/projects/gonseq/Building/Reference/.listing’ saved [3928]\n",
      "\n",
      "Removed ‘/shared/projects/gonseq/Building/Reference/.listing’.\n",
      "--2021-05-20 13:12:58--  ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/gencode.v37.primary_assembly.annotation.gtf.gz\n",
      "           => ‘/shared/projects/gonseq/Building/Reference/gencode.v37.primary_assembly.annotation.gtf.gz’\n",
      "==> CWD not required.\n",
      "==> PASV ... done.    ==> RETR gencode.v37.primary_assembly.annotation.gtf.gz ... done.\n",
      "Length: 45218446 (43M)\n",
      "\n",
      "100%[======================================>] 45,218,446  10.1MB/s   in 5.5s   \n",
      "\n",
      "2021-05-20 13:13:03 (7.86 MB/s) - ‘/shared/projects/gonseq/Building/Reference/gencode.v37.primary_assembly.annotation.gtf.gz’ saved [45218446]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logfile=\"${reffolder}wget_reference_files_downloads.log\"\n",
    "echo \"Some output is redirected to ${logfile} for record\"\n",
    "\n",
    "echo \"===== Annotation file retrieval ...\" >> ${logfile}\n",
    "wget -P \"${reffolder}\" -N \"${gtfgzurl}\"\n",
    "echo \"... done\" >> ${logfile}\n",
    "\n",
    "# to get record of used command line thus url and file size\n",
    "#history | tail -n 4 | head -n 1 >> ${logfile}  # not informative\n",
    "echo \"Used command is: wget -P ${reffolder} -N ${gtfgzurl}\"\n",
    "ls -lh \"${reffolder}\"*.gtf.gz >> ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use these two options:\n",
    "> ``-P PREFIX`` or ``--directory-prefix=PREFIX`` to specify output folder  \n",
    "> ``-N`` or ``--timestamping``: don't re-retrieve files unless newer than local  \n",
    "\n",
    "Some other available options exist and among them this one:\n",
    "> ``-a FILE`` or ``--append-output=FILE`` to append messages to FILE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some output is redirected to /shared/projects/gonseq/Building/Reference/wget_reference_files_downloads.log for record\n",
      "--2021-05-20 13:13:04--  ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/GRCh38.primary_assembly.genome.fa.gz\n",
      "           => ‘/shared/projects/gonseq/Building/Reference/.listing’\n",
      "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.197.74\n",
      "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.197.74|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /pub/databases/gencode/Gencode_human/release_37 ... done.\n",
      "==> PASV ... done.    ==> LIST ... done.\n",
      "\n",
      "    [ <=>                                   ] 3,928       --.-K/s   in 0.04s   \n",
      "\n",
      "2021-05-20 13:13:04 (90.8 KB/s) - ‘/shared/projects/gonseq/Building/Reference/.listing’ saved [3928]\n",
      "\n",
      "Removed ‘/shared/projects/gonseq/Building/Reference/.listing’.\n",
      "--2021-05-20 13:13:04--  ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/GRCh38.primary_assembly.genome.fa.gz\n",
      "           => ‘/shared/projects/gonseq/Building/Reference/GRCh38.primary_assembly.genome.fa.gz’\n",
      "==> CWD not required.\n",
      "==> PASV ... done.    ==> RETR GRCh38.primary_assembly.genome.fa.gz ... done.\n",
      "Length: 844691642 (806M)\n",
      "\n",
      "100%[======================================>] 844,691,642  103MB/s   in 7.5s   \n",
      "\n",
      "2021-05-20 13:13:12 (107 MB/s) - ‘/shared/projects/gonseq/Building/Reference/GRCh38.primary_assembly.genome.fa.gz’ saved [844691642]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "echo \"Some output is redirected to ${logfile} for record\"\n",
    "\n",
    "echo \"===== Genome sequence retrieval ...\" >> ${logfile}\n",
    "wget -P \"${reffolder}\" -N \"${fagzurl}\"\n",
    "echo \"... done\" >> ${logfile}\n",
    "\n",
    "# to get record of used command line thus url and file size\n",
    "#history | tail -n 4 | head -n 1 >> ${logfile}  # not informative\n",
    "echo \"Used command is: wget -P ${reffolder} -N ${fagzurl}\"\n",
    "ls -lh \"${reffolder}\"*.fa.gz >> ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3- Extract archive files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``STAR``, as other downstream tools, can't deal with compressed reference files.  \n",
    "Extracted files are quite big but compressed's ones are of rather affordable size. So we will keep them as is along with simplier filename assigment for extracted files (easier to handle, in particular when changing release and/or database source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p \"${reffolder}extracted/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primary annotation (notebook developped with GTF file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Extracting annotation file ...\n",
      "... done\n"
     ]
    }
   ],
   "source": [
    "echo \"===== Extracting annotation file ...\" |& tee -a  ${logfile}\n",
    "gtfgzfile=$(ls \"${reffolder}\"*.gtf.gz)\n",
    "gtffile=\"${reffolder}extracted/genome_annotation.gtf\"\n",
    "\n",
    "zcat ${gtfgzfile} > ${gtffile}\n",
    "echo \"... done\" |& tee -a  ${logfile}\n",
    "\n",
    "ls -lh \"${reffolder}extracted/\"*.gtf >> ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primary genome sequence file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Extracting sequence file ...\n",
      "... done\n"
     ]
    }
   ],
   "source": [
    "echo \"===== Extracting sequence file ...\" |& tee -a  ${logfile}\n",
    "fastagzfile=$(ls \"${reffolder}\"*.fa.gz)\n",
    "fastafile=\"${reffolder}extracted/genome_sequence.fa\"\n",
    "\n",
    "zcat ${fastagzfile} > ${fastafile}\n",
    "echo \"... done\" |& tee -a  ${logfile}\n",
    "\n",
    "ls -lh \"${reffolder}extracted/\"*.fa >> ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4- Get an eye in donwloaded files**\n",
    "Let's get an eye in those files to check they correspond to what we expect (or just discover file format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primary annotation (notebook developped with GTF file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##description: evidence-based annotation of the human genome (GRCh38), version 37 (Ensembl 103)\n",
      "##provider: GENCODE\n",
      "##contact: gencode-help@ebi.ac.uk\n",
      "##format: gtf\n",
      "##date: 2020-12-07\n",
      "chr1\tHAVANA\tgene\t11869\t14409\t.\t+\t.\tgene_id \"ENSG00000223972.5\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; level 2; hgnc_id \"HGNC:37102\"; havana_gene \"OTTHUMG00000000961.2\";\n",
      "chr1\tHAVANA\ttranscript\t11869\t14409\t.\t+\t.\tgene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_name \"DDX11L1-202\"; level 2; transcript_support_level \"1\"; hgnc_id \"HGNC:37102\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";\n",
      "chr1\tHAVANA\texon\t11869\t12227\t.\t+\t.\tgene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_name \"DDX11L1-202\"; exon_number 1; exon_id \"ENSE00002234944.1\"; level 2; transcript_support_level \"1\"; hgnc_id \"HGNC:37102\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";\n",
      "chr1\tHAVANA\texon\t12613\t12721\t.\t+\t.\tgene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_name \"DDX11L1-202\"; exon_number 2; exon_id \"ENSE00003582793.1\"; level 2; transcript_support_level \"1\"; hgnc_id \"HGNC:37102\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";\n",
      "chr1\tHAVANA\texon\t13221\t14409\t.\t+\t.\tgene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_name \"DDX11L1-202\"; exon_number 3; exon_id \"ENSE00002312635.1\"; level 2; transcript_support_level \"1\"; hgnc_id \"HGNC:37102\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";\n"
     ]
    }
   ],
   "source": [
    "head ${gtffile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primary genome sequence file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">chr1 1\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n"
     ]
    }
   ],
   "source": [
    "head ${fastafile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <b>II- Bluiding genome reference files</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes are small files that tell a program where to look for data in a large data file. They are required for mapping algorithms, as they allow for faster processing of millions reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1- Tool version and command line presentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.5a\n"
     ]
    }
   ],
   "source": [
    "STAR --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create reference genome files, the default command is: <br>\n",
    "<code>STAR --runMode genomeGenerate --genomeDir destination/folder \\\n",
    "      --genomeFastaFiles path/to/sequence.fa\n",
    "</code>\n",
    "\n",
    "<blockquote>\n",
    "    <code>--runMode genomeGenerate</code>, to switch to indexing step, else STAR is by defaul turned to alignReads (mapping step) <br>\n",
    "    <code>--genomeDir</code>, to specify folder where to put reference genome indexes <br>\n",
    "    <code>--genomeFastaFiles</code>, fasta file reference genome path (DOES NOT work with gz files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working on RNAseq data and need to have files that take splice junctions into account. Thus, we need to add following 2 parameters: <br>\n",
    "<code>--sjdbGTFfile path/to/annotation.file --sjdbOverhang readlengthnum</code>\n",
    "\n",
    "They stand for:\n",
    "<blockquote>\n",
    "    <code>--sjdbGTFfiles</code>, to specify where to find annotation file that contains exon positions, thus placing splice junction along genome sequence <br>\n",
    "    <code>--sjdbOverhang</code>, the maximum size that we expected to found on one splice junction side (<em>ideally, mate length-1</em>)\n",
    "</blockquote>\n",
    "\n",
    "For STAR, we can specify those two additional options either when genereating genome index files or when mapping sample. As we may be limited in computational ressources, we will add these items here and avoid memory-consuming operation repetition lately when iterating on all samples for mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2- Preparing command line variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used to develop this pipeline is based on reads sequenced on 50 bases.  \n",
    "As it may not be the case for yours, please check and/or change following value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawreadlength=50\n",
    "maxoneside=$((${rawreadlength}-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then create a folder to put those specific genomes indexes files, with an explicit name for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexfolder=\"${gohome}Reference/indexes_upto${maxoneside}bases/\"\n",
    "mkdir -p ${indexfolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding files, let's use again ``fastafile`` and ``gtffile`` variables, defined when extracting compressed files in previous step.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3- Running command line**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    Following <b>command is prepared for usage on a computational cluster</b> and was developped on the <i>Institut Français de Bioinformatique</i> (IFB)'s core cluster. We use a <i>Large</i> session defined as <b>10 CPU with 50 GB available for RAM</b>. \n",
    "</div>\n",
    "\n",
    "If you have limited computer ressources, please change following parameters directly in the command cell below. \n",
    "<blockquote>\n",
    "    <code>--limitGenomeGenerateRAM</code>, to set maximum available RAM (in bytes, standing for <i>octets</i> in French) for genome generation (integer, positive and not null, default value: 31000000000) <br>\n",
    "    <code>--runThreadN</code>, to limit the number of threads that <code>STAR</code> can use, it has to be set to the number of available cores\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen output is also redirected to /shared/projects/gonseq/Building/Reference/star_indexing_genome.log for record\n",
      "=== starting genome indexing ...\n",
      "May 20 13:13:51 ..... started STAR run\n",
      "May 20 13:13:51 ... starting to generate Genome files\n",
      "May 20 13:14:51 ..... processing annotations GTF\n",
      "May 20 13:15:27 ... starting to sort Suffix Array. This may take a long time...\n",
      "May 20 13:15:50 ... sorting Suffix Array chunks and saving them to disk...\n",
      "May 20 14:04:43 ... loading chunks from disk, packing SA...\n",
      "May 20 14:06:23 ... finished generating suffix array\n",
      "May 20 14:06:23 ... generating Suffix Array index\n",
      "May 20 14:09:43 ... completed Suffix Array index\n",
      "May 20 14:09:43 ..... inserting junctions into the genome indices\n",
      "May 20 14:12:19 ... writing Genome to disk ...\n",
      "May 20 14:12:22 ... writing Suffix Array to disk ...\n",
      "May 20 14:12:48 ... writing SAindex to disk\n",
      "May 20 14:12:50 ..... finished successfully\n",
      "\n",
      "real\t58m59.366s\n",
      "user\t393m48.061s\n",
      "sys\t9m47.630s\n",
      "... done\n"
     ]
    }
   ],
   "source": [
    "logfile=\"${gohome}Reference/star_indexing_genome.log\"\n",
    "echo \"Screen output is also redirected to ${logfile} for record\"\n",
    "\n",
    "echo \"=== starting genome indexing ...\" |& tee -a \"${logfile}\"\n",
    "echo \"operation starts at $(date)\" >> ${logfile}\n",
    "\n",
    "time STAR --runThreadN 9 --runMode genomeGenerate \\\n",
    "          --genomeDir \"${indexfolder}\" \\\n",
    "          --genomeFastaFiles \"${fastafile}\" \\\n",
    "          --sjdbGTFfile \"${gtffile}\" \\\n",
    "          --sjdbOverhang \"${maxoneside}\" \\\n",
    "          --limitGenomeGenerateRAM 48000000000 \\\n",
    "          |& tee -a \"${logfile}\"\n",
    "echo \"STAR indexing ends at $(date)\" >> ${logfile}\n",
    "\n",
    "# list files with their size\n",
    "ls -lh \"${indexfolder}\" >> ${logfile}\n",
    "\n",
    "echo \"... done\" |& tee -a \"${logfile}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is any issue, among all output files that STAR writes, start with ``Log.out``. It's a plain text file containing understood command line. It's quite verbose, that's very helpful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR version=2.7.5a\n",
      "STAR compilation time,server,dir=Tue Jun 16 12:17:16 EDT 2020 vega:/home/dobin/data/STAR/STARcode/STAR.master/source\n",
      "##### Command Line:\n",
      "STAR --runThreadN 9 --runMode genomeGenerate --genomeDir /shared/projects/gonseq/Building/Reference/indexes_upto49bases/ --genomeFastaFiles /shared/projects/gonseq/Building/Reference/extracted/genome_sequence.fa --sjdbGTFfile /shared/projects/gonseq/Building/Reference/extracted/genome_annotation.gtf --sjdbOverhang 49 --limitGenomeGenerateRAM 48000000000\n",
      "##### Initial USER parameters from Command Line:\n",
      "###### All USER parameters from Command Line:\n",
      "runThreadN                    9     ~RE-DEFINED\n",
      "runMode                       genomeGenerate     ~RE-DEFINED\n",
      "genomeDir                     /shared/projects/gonseq/Building/Reference/indexes_upto49bases/     ~RE-DEFINED\n",
      "genomeFastaFiles              /shared/projects/gonseq/Building/Reference/extracted/genome_sequence.fa        ~RE-DEFINED\n",
      "sjdbGTFfile                   /shared/projects/gonseq/Building/Reference/extracted/genome_annotation.gtf     ~RE-DEFINED\n",
      "sjdbOverhang                  49     ~RE-DEFINED\n",
      "limitGenomeGenerateRAM        48000000000     ~RE-DEFINED\n",
      "##### Finished reading parameters from all sources\n",
      "\n",
      "##### Final user re-defined parameters-----------------:\n",
      "runMode                           genomeGenerate\n",
      "runThreadN                        9\n",
      "genomeDir                         /shared/projects/gonseq/Building/Reference/indexes_upto49bases/\n",
      "genomeFastaFiles                  /shared/projects/gonseq/Building/Reference/extracted/genome_sequence.fa   \n",
      "limitGenomeGenerateRAM            48000000000\n",
      "sjdbGTFfile                       /shared/projects/gonseq/Building/Reference/extracted/genome_annotation.gtf\n",
      "sjdbOverhang                      49\n",
      "\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "head -n 25 \"${indexfolder}Log.out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4- Genome extracted files removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how many disk space Reference files use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3G\t/shared/projects/gonseq/Building/Reference/extracted\n",
      "28G\t/shared/projects/gonseq/Building/Reference/indexes_upto49bases\n",
      "33G\t/shared/projects/gonseq/Building/Reference/\n"
     ]
    }
   ],
   "source": [
    "du -h ${reffolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genome extracted file is no more used, let's remove it to spare some space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28G\t/shared/projects/gonseq/Building/Reference/indexes_upto49bases\n",
      "29G\t/shared/projects/gonseq/Building/Reference/\n"
     ]
    }
   ],
   "source": [
    "rm \"${reffolder}extracted/genome_sequence.fa\"  # line changed after run\n",
    "du -h ${reffolder}\n",
    "#ls -lh \"${reffolder}extracted/\"  # suggested additionnal line to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>III- Mapping samples on reference genome</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1- Tool version and command line presentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little stop to discover ``STAR`` version as you may have skiped genome indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.5a\n"
     ]
    }
   ],
   "source": [
    "STAR --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rather simple version of commandline or mapping is: <br>\n",
    "<code>STAR --genomeDir path/to/indexes/folder/ \\\n",
    "      --readFilesIn path/to/read1.fastq.gz path/to/read2.fastq.gz \\\n",
    "      --readFilesCommand zcat \\\n",
    "      --outSAMtype BAM SortedByCoordinate \\\n",
    "      --quantMode GeneCounts \\\n",
    "</code>\n",
    "\n",
    "<blockquote>\n",
    "    <code>--readFilesIn</code> for <code>Read</code> (for Single End data) or both <code>Read1 Read2</code> (for Paired End data) as full paths to files that contain input read(s)\n",
    "    <code>--readFilesCommand</code>, to indicate tool that can handle read file format. <code>STAR</code> allow user a direct use of compressed file but rely on available tools <br>\n",
    "    <br>\n",
    "    <code>--outSAMtype word1 word2</code>, to set output file format we want (default, SAM). <br>\n",
    "    Options for <code>word1</code> are <code>BAM</code>, <code>SAM</code> and <code>NoneNone</code> (no SAM/BAM output). <br>\n",
    "    Options for <code>word2</code> are <code>Unsorted</code> or <code>SortedByCoordinate</code>. This option will allocate extra memory for sorting which can be specified by <code>--limitBAMsortRAM</code>.<br>\n",
    "    <br>\n",
    "    <code>--quantMode</code> (default, <i>none</i>), to activate and ask for one or several quantification outputs.  <br>\n",
    "    Available options are: <code>GeneCounts</code> and <code>TranscriptomeSAM</code>. The latter will generate an output SAM/BAM alignments to transcriptome into a separate file while the former only generates a text file with count reads per gene.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As ``_Aligned.toTranscriptome.out.bam`` generated files for downstream transcript level are as big or bigger than ``_Aligned.sortedByCoord.out.bam``, only required for downstream quantification analysis by ``FeatureCounts``, we will focus on gene level quantification mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use transcript level qualification, we have previously successfully used below options: <br>\n",
    "<code>--quantMode TranscriptomeSAM GeneCounts</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2- Preparing command line variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we still have all ``.fastq.gz`` files where we left them. We count files that do no include *_removed* in their name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "ls \"${gohome}Data/fastq/fastp/\" | grep -v -e \"_removed\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here create destination folder for aligned ``.bam`` and other output files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedfolder=\"${gohome}Results/star/\"\n",
    "mkdir -p ${mappedfolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and remember matched ``Results/`` destination folder for log files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfolder=\"${gohome}Results/logfiles/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3- Running command line**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    Following <b>command is prepared for usage on a computational cluster</b> and was developped on the <i>Institut Français de Bioinformatique</i> (IFB)'s core cluster. We use a <i>Large</i> session defined as <b>10 CPU with 50 GB available for RAM</b>. \n",
    "</div>\n",
    "\n",
    "If you have limited computer ressources, please change following parameters directly in the command cell below. \n",
    "<blockquote>\n",
    "    <code>--limitBAMsortRAM</code>, to set maximum available RAM (in bytes, standing for <i>octets</i> in French) for sorting <code>.bam</code> file (integer, positive). <i>Note: Value can be null only if <code>--genomeLoad</code> option is unchanged, thus it will be set to the genome index size.</i> <br>\n",
    "    <code>--runThreadN</code>, to limit the number of threads that <code>STAR</code> can use, it has to be set to the number of available cores\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen output is redirected to /shared/projects/gonseq/Building/Results/logfiles/star_mapping_samples.log\n",
      "====== Processing sampleID: SRR7430706...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430707...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430708...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430709...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430710...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430711...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430712...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430713...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430738...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430739...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430740...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430741...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430742...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430743...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430744...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430745...\n",
      "...done\n",
      "\n",
      "real\t157m2.801s\n",
      "user\t963m29.190s\n",
      "sys\t65m41.767s\n",
      "STAR generated 127 files during this step.\n"
     ]
    }
   ],
   "source": [
    "logfile=\"${logfolder}star_mapping_samples.log\"\n",
    "echo \"Screen output is redirected to ${logfile}\"\n",
    "\n",
    "# as time command does not redirect output\n",
    "echo \"operation starts at $(date)\" >> ${logfile}\n",
    "\n",
    "time for read1 in $(ls \"${gohome}Data/fastq/fastp/\"*_1.fastp.fastq.gz); do\n",
    "\n",
    "    # handling names with the sample name\n",
    "    samplenum=$(basename ${read1} | cut -d\"_\" -f1)\n",
    "    echo \"====== Processing sampleID: ${samplenum}...\" | tee -a ${logfile}\n",
    "    read2=$(echo ${read1} | sed 's#_1#_2#')\n",
    "\n",
    "    echo \"STAR starts at $(date)\" >> ${logfile}\n",
    "    # STAR working\n",
    "    STAR --runThreadN 9 --runMode alignReads \\\n",
    "        --genomeDir \"${indexfolder}\" \\\n",
    "        --readFilesIn \"${read1}\" \"${read2}\" \\\n",
    "        --readFilesCommand zcat \\\n",
    "        --outFileNamePrefix \"${mappedfolder}${samplenum}_\" \\\n",
    "        --outSAMtype BAM SortedByCoordinate \\\n",
    "        --outSAMattributes All \\\n",
    "        --outReadsUnmapped Fastx \\\n",
    "        --limitBAMsortRAM 48000000000 \\\n",
    "        --quantMode GeneCounts \\\n",
    "        &>> ${logfile}\n",
    "    echo \"STAR ends at $(date)\" >> ${logfile}\n",
    "    \n",
    "    echo \"...done\" | tee -a ${logfile} \n",
    "    \n",
    "done\n",
    "echo \"operation ends at $(date)\" >> ${logfile}\n",
    "\n",
    "echo \"=== files created during mapping step ===\" >> ${logfile}\n",
    "ls -lh \"${mappedfolder}\" >> ${logfile}\n",
    "\n",
    "echo \"STAR generated $(ls \"${mappedfolder}\" | wc -l) files during this step.\" \\\n",
    "     | tee -a ${logfile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16M\t/shared/projects/gonseq/Building/Results/multiqc\n",
      "8.4M\t/shared/projects/gonseq/Building/Results/fastp\n",
      "244K\t/shared/projects/gonseq/Building/Results/logfiles\n",
      "34M\t/shared/projects/gonseq/Building/Results/fastqc\n",
      "112G\t/shared/projects/gonseq/Building/Results/star\n",
      "4.0K\t/shared/projects/gonseq/Building/Results/.ipynb_checkpoints\n",
      "112G\t/shared/projects/gonseq/Building/Results\n",
      "154G\t/shared/projects/gonseq/Building/Data/fastq\n",
      "46G\t/shared/projects/gonseq/Building/Data/sra\n",
      "44K\t/shared/projects/gonseq/Building/Data/info\n",
      "36K\t/shared/projects/gonseq/Building/Data/.ipynb_checkpoints\n",
      "199G\t/shared/projects/gonseq/Building/Data\n",
      "4.0K\t/shared/projects/gonseq/Building/.ipynb_checkpoints\n",
      "104K\t/shared/projects/gonseq/Building/Pipeline/.ipynb_checkpoints\n",
      "208K\t/shared/projects/gonseq/Building/Pipeline\n",
      "28G\t/shared/projects/gonseq/Building/Reference/indexes_upto49bases\n",
      "29G\t/shared/projects/gonseq/Building/Reference\n",
      "339G\t/shared/projects/gonseq/Building/\n",
      "339G\ttotal\n"
     ]
    }
   ],
   "source": [
    "du -ch -d2 ${gohome}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Processing sampleID: SRR7430706...\n",
      "May 20 18:43:45 ..... started STAR run\n",
      "May 20 18:43:45 ..... loading genome\n",
      "May 20 18:44:36 ..... started mapping\n",
      "May 20 18:51:09 ..... finished mapping\n",
      "May 20 18:51:10 ..... started sorting BAM\n",
      "May 20 18:52:50 ..... finished successfully\n",
      "...done\n"
     ]
    }
   ],
   "source": [
    "read1=\"${gohome}Data/fastq/fastp/SRR7430706_1.fastp.fastq.gz\"\n",
    "\n",
    "samplenum=$(basename ${read1} | cut -d\"_\" -f1)\n",
    "echo \"====== Processing sampleID: ${samplenum}...\" | tee -a ${logfile}\n",
    "read2=$(echo ${read1} | sed 's#_1#_2#')\n",
    "\n",
    "echo \"STAR starts at $(date)\" >> ${logfile}\n",
    "# STAR working\n",
    "STAR --runThreadN 9 --runMode alignReads \\\n",
    "    --genomeDir \"${indexfolder}\" \\\n",
    "    --readFilesIn \"${read1}\" \"${read2}\" \\\n",
    "    --readFilesCommand zcat \\\n",
    "    --outFileNamePrefix \"${mappedfolder}${samplenum}_\" \\\n",
    "    --outSAMtype BAM SortedByCoordinate \\\n",
    "    --outSAMattributes All \\\n",
    "    --outReadsUnmapped Fastx \\\n",
    "    --limitBAMsortRAM 48000000000 \\\n",
    "    --quantMode GeneCounts \\\n",
    "    |& tee -a ${logfile}\n",
    "echo \"STAR ends at $(date)\" >> ${logfile}\n",
    "\n",
    "echo \"...done\" | tee -a ${logfile}\n",
    "\n",
    "echo \"=== files created during SRR7430706 mapping step ===\" >> ${logfile}\n",
    "ls -lh \"${mappedfolder}\" | grep \"SRR7430706\" >> ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>IV- Building sample ``.bam`` indexes with ``samtools``</b>\n",
    "\n",
    "We will here index ``.bam`` files to produce the companion ``.bai``. Such files help, in particular, going faster to visualize alignements ``.bam`` file in genome browser viewer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1- Tool version**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands used for this part belong to a large package of utilities that are very useful to manage those types of files: SAMTOOLS (http://www.htslib.org/).\n",
    "\n",
    "Let's check first which version of SAMTOOLS we are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samtools 1.10\n",
      "Using htslib 1.10.2\n",
      "Copyright (C) 2019 Genome Research Ltd.\n"
     ]
    }
   ],
   "source": [
    "samtools --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple commandline syntax is: <code>samtools index path/to/file.bam</code>\n",
    "  \n",
    "There is no need to provide a name of the ouput file, as it should always be the same as the corresponding ``.bam`` file, expect for the added ``.bai`` suffix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2- Creating files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen output is redirected to /shared/projects/gonseq/Building/Results/logfiles/samtools_indexing_samples.log\n",
      "====== Processing sampleID: SRR7430706...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430707...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430708...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430709...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430710...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430711...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430712...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430713...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430738...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430739...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430740...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430741...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430742...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430743...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430744...\n",
      "...done\n",
      "====== Processing sampleID: SRR7430745...\n",
      "...done\n",
      "\n",
      "real\t18m43.168s\n",
      "user\t17m39.576s\n",
      "sys\t0m56.905s\n",
      "samtools index generated 16 files during this step.\n"
     ]
    }
   ],
   "source": [
    "logfile=\"${logfolder}samtools_indexing_samples.log\"\n",
    "echo \"Screen output is redirected to ${logfile}\"\n",
    "\n",
    "# as time command does not redirect output\n",
    "echo \"operation starts at $(date)\" >> ${logfile}\n",
    "\n",
    "time for bamfile in $(ls \"${mappedfolder}\"*_Aligned.sortedByCoord.out.bam); do\n",
    "\n",
    "    samplenum=$(basename ${bamfile} | cut -d\"_\" -f1)\n",
    "    echo \"====== Processing sampleID: ${samplenum}...\" | tee -a ${logfile}\n",
    "    \n",
    "    echo \"samtools index starts at $(date)\" >> ${logfile}\n",
    "    samtools index \"${bamfile}\" \\\n",
    "             &>> ${logfile}\n",
    "    echo \"samtools index ends at $(date)\" >> ${logfile}\n",
    "    \n",
    "    echo \"...done\" | tee -a ${logfile} \n",
    "    \n",
    "done\n",
    "echo \"operation ends at $(date)\" >> ${logfile}\n",
    "\n",
    "echo \"=== files created during indexing step ===\" >> ${logfile}\n",
    "ls -lh \"${mappedfolder}\"*.bai >> ${logfile}\n",
    "\n",
    "echo \"samtools index generated $(ls \"${mappedfolder}\"*.bai | wc -l) files during this step.\" \\\n",
    "     | tee -a ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    If one or more <code>.bai</code> files are missing, there should be an error in their matched <code>.bam</code> file. Have a look into generated <code>.log</code> file. <br>\n",
    "    When there is not enough disk space during mapping process, <code>.bam</code> file may be incomplete: you can find <i>missing EOF block when one should be present</i> error for this sample. <br>\n",
    "    Enhance, please be sure before you start again mapping step that you have at least 5 times more space than one's sample <code>.fastq</code> files size (or 10 times if you activate <code>TranscriptomeSAM</code> along with <code>GeneCounts</code>).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3- Get an eye on used disk space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0M\t/shared/projects/gonseq/Building/Results/multiqc/2_fastp-fastq-files_data\n",
      "2.0M\t/shared/projects/gonseq/Building/Results/multiqc/1_raw-fastq-files_data\n",
      "1.7M\t/shared/projects/gonseq/Building/Results/multiqc/1_raw-fastq-files_plots\n",
      "2.0M\t/shared/projects/gonseq/Building/Results/multiqc/2_fastp-fastq-files_plots\n",
      "1.2M\t/shared/projects/gonseq/Building/Results/multiqc/.ipynb_checkpoints\n",
      "16M\t/shared/projects/gonseq/Building/Results/multiqc\n",
      "4.0K\t/shared/projects/gonseq/Building/Results/fastp/.ipynb_checkpoints\n",
      "8.4M\t/shared/projects/gonseq/Building/Results/fastp\n",
      "112K\t/shared/projects/gonseq/Building/Results/logfiles/.ipynb_checkpoints\n",
      "256K\t/shared/projects/gonseq/Building/Results/logfiles\n",
      "34M\t/shared/projects/gonseq/Building/Results/fastqc\n",
      "4.0K\t/shared/projects/gonseq/Building/Results/star/.ipynb_checkpoints\n",
      "117G\t/shared/projects/gonseq/Building/Results/star\n",
      "4.0K\t/shared/projects/gonseq/Building/Results/.ipynb_checkpoints\n",
      "118G\t/shared/projects/gonseq/Building/Results\n",
      "75G\t/shared/projects/gonseq/Building/Data/fastq/raw\n",
      "79G\t/shared/projects/gonseq/Building/Data/fastq/fastp\n",
      "154G\t/shared/projects/gonseq/Building/Data/fastq\n",
      "2.6G\t/shared/projects/gonseq/Building/Data/sra/SRR7430707\n",
      "2.8G\t/shared/projects/gonseq/Building/Data/sra/SRR7430711\n",
      "2.9G\t/shared/projects/gonseq/Building/Data/sra/SRR7430740\n",
      "3.1G\t/shared/projects/gonseq/Building/Data/sra/SRR7430738\n",
      "5.2G\t/shared/projects/gonseq/Building/Data/sra/SRR7430745\n",
      "3.2G\t/shared/projects/gonseq/Building/Data/sra/SRR7430710\n",
      "2.7G\t/shared/projects/gonseq/Building/Data/sra/SRR7430709\n",
      "2.3G\t/shared/projects/gonseq/Building/Data/sra/SRR7430744\n",
      "3.1G\t/shared/projects/gonseq/Building/Data/sra/SRR7430708\n",
      "2.2G\t/shared/projects/gonseq/Building/Data/sra/SRR7430741\n",
      "3.0G\t/shared/projects/gonseq/Building/Data/sra/SRR7430713\n",
      "2.5G\t/shared/projects/gonseq/Building/Data/sra/SRR7430743\n",
      "3.0G\t/shared/projects/gonseq/Building/Data/sra/SRR7430706\n",
      "2.7G\t/shared/projects/gonseq/Building/Data/sra/SRR7430739\n",
      "2.5G\t/shared/projects/gonseq/Building/Data/sra/SRR7430712\n",
      "2.7G\t/shared/projects/gonseq/Building/Data/sra/SRR7430742\n",
      "46G\t/shared/projects/gonseq/Building/Data/sra\n",
      "8.0K\t/shared/projects/gonseq/Building/Data/info/.ipynb_checkpoints\n",
      "44K\t/shared/projects/gonseq/Building/Data/info\n",
      "36K\t/shared/projects/gonseq/Building/Data/.ipynb_checkpoints\n",
      "199G\t/shared/projects/gonseq/Building/Data\n",
      "4.0K\t/shared/projects/gonseq/Building/.ipynb_checkpoints\n",
      "104K\t/shared/projects/gonseq/Building/Pipeline/.ipynb_checkpoints\n",
      "208K\t/shared/projects/gonseq/Building/Pipeline\n",
      "28G\t/shared/projects/gonseq/Building/Reference/indexes_upto49bases\n",
      "29G\t/shared/projects/gonseq/Building/Reference\n",
      "345G\t/shared/projects/gonseq/Building/\n"
     ]
    }
   ],
   "source": [
    "du -h -d3 ${gohome}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For current project, we can use up to 600 Gb. As next steps are less space consuming, some cleaning shouln't be required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "___\n",
    "\n",
    "Now we go on to check mapping quality.\n",
    "\n",
    "**=> Step 5: Quality post mapping** \n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
